,_1
0,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
1,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
2,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
3,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
4,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
5,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
6,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
7,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
8,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
9,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
10,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
11,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
12,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
13,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
14,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
15,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
16,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
17,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
18,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
19,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
20,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
21,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
22,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
23,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
24,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
25,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
26,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
27,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
28,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
29,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
30,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
31,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
32,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
33,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
34,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
35,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
36,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
37,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
38,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
39,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
40,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
41,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
42,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
43,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
44,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
45,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
46,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
47,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
48,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
49,"지속적 전문 교육 (CPE) 정책 갱신일: 2014년 1월 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 1 목차 개요 ..................................................................................................2 인증 요건 .........................................................................................2 일반 요건 연간 및 3년 인증 기간 CISA 유지비 납부 및 CPE 시간 보고 연간 준수 통지 CISA 로고의 사용 CPE 시간의 감사 ............................................................................3 기록 보관 .........................................................................................3 자격 취소 .........................................................................................3 재심 및 항의 ....................................................................................3 퇴직 및 휴직 CISA 자격 .................................................................3 퇴직 CISA 자격 휴직 CISA 자격 전문 교육 인정 활동 ........................................................................4 CPE 시간의 계산 ............................................................................5 연락 정보 .........................................................................................5 직업윤리강령 ...................................................................................6 출석 확인서 ......................................................................................7 기록 양식 .........................................................................................8 2 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 개요 이 지속적 전문 교육(CPE) 정책의 목표는 모든 국제 공인 정보시스템 감사사(CISA: Certified Information Systems Auditor)가 정보시스템 감사, 통제 및 보안 분야에서 적절한 수준의 최신 지식과 실력을 유지할 수 있도록 보장하는 것입니다. CPE 정책을 성공적으로 준수하는 CISA는 더 나은 교육을 통해 정보 시스템 및 기술을 올바르게 평가하고 조직에 리더십과 가치를 제공할 수 있습니다. CPE 요건을 제정하는 책임은 CISA 자격심사위원회(CISA Certification Committee)에 있습니다. 위원회에서는 지속적 전문 교육 과정과 요건의 감독을 통해 이러한 과정과 요건의 적용 가능성을 보장합니다. 인증 요건 일반 요건 CISA CPE 정책은 연간 및 3년의 인증 기간 동안 일정한 시간 이상의 CPE를 이수해야 합니다. CISA는 자격증을 유지하기 위해 다음과 같은 요건을 충족해야 합니다. ■ 연간 20시간 이상의 CPE 이수 및 보고. 이러한 시간은 CISA 관련 업무를 수행하는데 필요한 CISA 지식 또는 능력을 유지하고 향상시키기에 적절해야 합니다. 전문 활동이 각 자격증의 직무 관련 지식을 충족하는 데 해당할 경우 이 시간을 여러 ISACA 자격증의 CPE 요건을 충족하기 위해 사용할 수 있습니다. ■ 매년 ISACA 국제 본부에 CPE 유지비 납부 ■ 3년의 보고 기간 동안 120시간 이상의 CPE 이수 및 보고 ■ 연례 감사 대상으로 선정된 경우 감사에 응하고 필수적인 CPE 활동 서류 제출 ■ ISACA 직업윤리강령 준수 이러한 인증 요건을 준수하지 못할 경우 CISA 자격증이 취소됩니다. 또한, 모든 자격증은 ISACA의 소유이기 때문에, 취소된 자격증은 즉시 폐기해야 합니다. 연간 및 3년 인증 기간 연간 보고 기간은 매년 1월 1일에 시작합니다. 3년 인증 기간은 달라지며 매년 연간 유지비 청구서와 연간 준수 확인서에 표시됩니다. 신규 자격 인증을 받은 CISA의 연간 및 3년 인증 기간은 인증 받은 다음 해 1월 1일에 시작합니다. 인증 받은 해에 이수한 CPE 시간을 반드시 보고할 필요는 없습니다. 그러나, 인증일부터 당해년도 12월 31일까지 이수한 시간은 최초 보고 기간에 이수한 시간으로 사용하여 보고할 수 있습니다. CISA 유지비 납부 및 CPE 시간 보고 CISA 인증을 갱신하려면 유지비를 납부하고 CPE 시간을 보고해야 합니다. 유지비 청구서는 ISACA가 매년 3사분기에 모든 CISA에게 이메일과 서신을 통해 발송합니다. 연간 유지비는 www.isaca.org/renew에서 온라인으로 납부할 수 있습니다. CPE 시간은 획득할 때마다 웹 사이트의 MyISACA > MyCertifications > Manage My CPE 페이지에서 기록 가능합니다. 인증서는 연간 갱신 청구서에 정보를 제출함으로써 갱신 가능합니다. 자격증을 유지하기 위해서는 1월 15일까지 유지비를 납부하고 CPE 시간을 보고해야 합니다. 연간 준수 통지 기한 내에 필요한 CPE 시간 수를 보고하고 유지비를 전액 납부한 CISA는 ISACA 국제 본부로부터 확인 통지서를 받게 됩니다. 이 확인 통지서에는 해당 연간 보고 기간 동안 인정된 CPE 시간 수, 3년 인증 기간 내에서 지난 해까지 보고된 시간, 지정된 3년의 인증 기간 동안 자격을 유지하기 위해 필요한 시간 수가 기재됩니다. 이 확인 통지서에 오류 또는 누락된 사항이 있을 경우 즉시 ISACA 국제 본부에 통지하는 것은 각 CISA의 책임입니다. CISA 로고의 사용 CISA 로고의 개인적인 사용(명함, 웹 사이트, 마케팅 또는 홍보 자료 등)은 해당 개인의 제품이나 서비스에 대한 ISACA의 보증 또는 제휴를 의미할 수 있기 때문에 허용되지 않습니다. CISA는 자신의 이름 뒤에 CISA 약어를 사용할 수 있습니다(예: 홍길동, CISA). 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 3 CPE 시간의 감사 매년 CISA를 무작위로 선정하여 감사를 실시합니다. 선정된 CISA는 이전에 보고한 활동에 대해 전문 교육 인정 활동(Qualifying Professional Education Activities)에 설명된 기준을 충족하는 서면 증거 자료를 제출해야 합니다. 제출한 서류는 반환되지 않으므로 사본을 제출하십시오. 특정한 전문 교육 활동을 지속적 전문 교육 시간으로 인정할 것인지 여부는 CISA 자격심사위원회(Certification Committee)에서 결정합니다. 감사에 응하지 않을 경우에는 CISA 자격증이 취소됩니다. 기록 보관 CISA는 ISACA에 보고한 CPE 활동을 입증하는 서류를 입수하여 보관해야 합니다. 서류는 각각의 3년 보고 기간이 종료된 후 12개월 동안 보관해야 하며 서신, 수료증, 출석 등록부, 출석 확인서(본 정책에 첨부되어 있음) 또는 이수를 증명하는 기타 독립 증명서의 형태여야 합니다. 각 기록에는 최소한 출석자의 이름, 후원 조직의 이름, 활동 제목, 활동 내용, 활동 날짜 및 이수한 CPE 시간 수가 포함되어야 합니다. 자격 취소 CISA CPE 정책을 준수하지 않은 CISA는 CISA 자격증이 취소되며 더 이상 CISA로서 활동이 허용되지 않습니다. CISA 자격증이 취소된 경우에는 다시 CISA 시험을 치러 합격한 다음 CISA 자격증 신청서를 제출해야 합니다. 재심 및 항의 CPE 정책을 준수하지 않아서 인증서가 거절되었지만 나중에 다시 부활하고자 하는 경우에는 추가 부활 비용인 $50가 나중에 부과될 수 있습니다. 이러한 부활 비용은 2013년 1월 1일 이후에 부활한 회원에게 적용되며(취소가 60일 이상 계류 상태인 경우) 인증을 받은 개인이 CPE 정책을 준수하기 위해 필요한 기존 또는 현재 인증 유지비에 추가됩니다. 자격증 시험 응시자, 자격증 지원자 또는 자격증 취득자 개인이 제기한 이의 신청은 재량에 따라 실시되며 그 비용은 시험 응시자, 지원자 또는 개인이 지불해야 합니다. 퇴직 및 휴직 CISA 자격 퇴직 CISA 자격 CISA는 55세가 넘어 CISA 직업에서 은퇴하거나 영구적인 장애로 인해 IS 감사, 통제 및 보안 전문가의 임무를 수행할 수 없을 경우, 퇴직 CISA 자격을 신청할 수 있습니다. 이 자격을 부여받은 CISA는 더 이상 CPE를 이수할 필요가 없지만, 감액된 연간 유지비를 납부해야 합니다. 휴직 CISA 자격 더 이상 IS 감사, 통제 및 보안 전문가로서 일하고 있지 않은 CISA는 휴직 CISA 자격을 신청할 수 있습니다 휴직 CISA 자격 신청은 연간 유지비 청구서와 함께 1월 15일까지 ISACA에 접수해야 합니다. 이 자격을 부여받은 CISA는 CPE를 이수할 필요가 없지만, 연간 유지비는 납부해야 합니다. 휴직을 마친 CISA은 활동 상태로 복귀해야 합니다. 이전에는 허용되었지만 휴직 중이거나 은퇴한 CISA는 이제 명함에 ""CISA"" 또는 "" 휴직중 CISA""이라고 기재할 수 없습니다. 퇴직 또는 휴직 CISA 자격을 신청하고자 하는 CISA는 CISA 휴직 또는 퇴직 자격을 위한 적절한 신청서 형식을 기입해서 제출해야 합니다. 자세한 내용은 자격증 관리부서에 전화(+1.847.660.5660), 팩스(+1.847.253.1755) 또는 이메일(certification@isaca.org)을 통해 신청할 수 있습니다. 4 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 전문 교육 인정 활동 CPE로 인정되는 활동에는 기술 및 관리 교육이 포함됩니다. 이러한 교육 내용은 전문직 발전의 적절한 균형을 유지하기 위해 정보 시스템의 평가 또는 감사, 통제, 보안이나 관리 기술(www.isaca.org/cisajobpractice)의 개선에 직접 적용할 수 있어야 합니다. 관리 기술과 관련된 CPE 시간은 감사 및/또는 감사 자원의 관리와 관련된 것이어야 합니다. 현장 실습 활동은 특정 전문 교육 인정 활동에 속하지 않는 한 CPE 시간으로 인정되지 않습니다. Microsoft Word 또는 Excel과 같이 기본적인 사무용 소프트웨어의 교육은 CPE로 인정되지 않습니다. 특정 활동의 경우 연간 CPE로 인정 받을 수 있는 시간에 제한이 있습니다. CPE는 25분 단위로 보고될 수 있습니다. 다음은 CISA 자격심사위원회(CISA Certification Committee)의 승인을 받고 CPE로 인정되는 활동 범주 및 시간 제한입니다. ■ ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA 컨퍼런스, 세미나, 워크샵, 지부 프로그램과 회의 및 관련 활동이 포함됩니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). ISACA 지부 회의에 참석할 경우 실제 회의 시간에 관계 없이 최소 1시간을 이수한 것으로 간주됩니다. 지부 프로그램과 회의는 ISACA 데이터베이스에 모두 보고되지는 않는다는 점에 유의하십시오. 참석 확인증을 보관해 두십시오. ■ 비 ISACA 전문 교육 활동 및 회의(무제한): 이러한 활동에는 ISACA가 후원하지 않는 사내 교육, 대학 교과과정, 컨퍼런스, 세미나, 워크샵과 전문가 회의 및 관련 활동이 포함됩니다. 또한 CISA의 IS 감사, 통제 및 보안 또는 감사 관련 관리 지식이나 기술을 향상시키는 자격증 리뷰 과정을 통해서도 CPE를 이수할 수 있습니다. CISA는 이러한 활동에 실제로 참여한 시간 수만큼 CPE를 이수한 것으로 간주됩니다. (CPE 시간 계산 부분을 참조하십시오). 그러나 대학 온라인 과정을 포함하여 관련 분야의 대학 교과과정을 성공적으로 이수한 경우에는 학기 이수 시간당 15시간의 CPE 교육과 분기 이수 시간당 10시간의 CPE 시간을 이수한 것으로 간주됩니다(학기 = 15주 강의, 분기 = 10주 강의). ■ 독학 과정(무제한): 이러한 활동에는 CPE 시간을 제공하는 체계적으로 설계된 독학 과정이 포함됩니다. 이 과정은 해당 과정 제공자가 수료증을 발급하고 수료증에 해당 과정을 통해 이수한 CPE 시간 수가 기재되는 경우에만 인정됩니다. ISACA® Journal 시험에서 합격 점수를 받은 경우 또한 1시간의 CPE를 이수한 것으로 간주됩니다. ISACA가 후원하는 온라인 eLearning 프리젠테이션 행사(예를 들어, 가상 무역쇼, Webinars 등)에 참여하는 ISACA 회원은 추가 CPE를 받을 수 있습니다. eLearning 행사의 업데이트된 목록은 www.isaca.org/elearning을 방문하십시오. ISACA® Journal 시험과 ISACA eLearning 활동은 보유하고 있는 각 ISACA 자격증에 대해 (두 번 이상) 사용할 수 있습니다. ■ 벤더 영업/마케팅 프리젠테이션(연 10시간 이내): 이러한 활동에는 정보 시스템의 평가와 관련된 벤더 제품 또는 시스템 관련 영업 프리젠테이션이 포함됩니다. ■ 강의/강연/프리젠테이션(무제한): 이러한 활동에는 정보 시스템의 평가와 관련된 전문 교육 프리젠테이션 개발과 발표 및 독학/원격 교육 과정의 개발이 포함됩니다. 프리젠테이션 및 교과과정(모든 유형)의 경우, 첫 번째 발표 시에는 프리젠테이션 시간 또는 교과과정의 예상 수강 시간의 다섯 배에 해당하는 CPE 시간을 이수한 것으로 간주되며(예: 2시간의 프리젠테이션은 10시간의 CPE 시간에 해당) 두 번째 발표 시에는 실제 프리젠테이션 시간만큼 CPE 시간을 이수한 것으로 간주됩니다. 세 번째 발표부터는 내용이 본질적으로 수정되지 않는 한 CPE 시간을 이수한 것으로 인정되지 않습니다. 독학/원격 교육 과정의 경우, 해당 교과과정의 업그레이드/유지관리에 소요된 1시간마다 1시간의 CPE 시간을 이수한 것으로 간주됩니다. 단, 교과과정의 예상 수강 시간의 두 배로 제한됩니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 5 ■ 기사, 전공논문 및 서적 출판(무제한): 이러한 활동에는 정보시스템 감사 및 통제 분야에 직접 관련된 자료의 출판 및/또는 논평이 포함됩니다. 제출 자료는 공식 출판물 또는 웹 사이트의 형태여야 하며 요청시 기사 사본 또는 웹사이트 주소를 제시할 수 있어야 합니다. 서적 및 전공논문의 경우 목차와 제목 페이지를 제출할 수 있어야 합니다. 이러한 활동의 경우 해당 자료를 저술 또는 논평하는 데 소요된 실제 시간을 CPE 시간으로 인정합니다. ■ 시험 문제 개발 및 검토(무제한): 이 활동은 CISA 시험 또는 리뷰 자료 항목의 개발 또는 검토와 관련이 있습니다. ISACA CISA 항목 검토 위원회가 인정하는 각 문제당 2시간의 CPE를 이수한 것으로 간주됩니다. 이 시간은 모든 ISACA 자격증에 대해 여러 번 사용할 수 있습니다. 공식적인 항목 검토 과정에 대한 실제 이수 시간에 대한 증명서가 제공됩니다. ■ 관련 전문 시험 합격(무제한): 이 활동은 다른 관련 전문 시험에 합격하는 것과 관련이 있습니다. 합격 점수를 받은 경우 각 시험 시간당 2시간의 CPE 시간을 이수한 것으로 인정됩니다. ■ ISACA 이사회/위원회 근무(ISACA 자격증 당 연 20시간 이내): 이러한 활동에는 ISACA 이사회, 위원회, 하위 위원회, 특별 작업반에 참여하거나 ISACA 지부의 임직원으로서 활동하는 경우가 포함됩니다. 실제 참가 시간당 1시간의 CPE를 이수한 것으로 인정됩니다. 실제 참가 시간에는 지부 웹 사이트의 개발, 구현 및/또는 유지관리가 포함되며, 단 이에 국한되지는 않습니다. 이러한 활동은 보유하고 있는 각 ISACA 자격증에 대해 두 번 이상 사용할 수 있습니다. ■ IS 감사 및 통제 전문 분야에 기여(CISA 보고 시간과 관련된 모든 활동에 대해 총 연 20시간 이내): 이 활동에는 ISACA 및 기타 단체를 위해 수행한 IS 감사 및 통제 분야에 기여한 활동(즉, 연구 개발, 자격증 리뷰 설명서 개발, 지식 센터 공헌자, 전문가 심사)이 포함됩니다. CPE 시간은 소요된 실제 시간으로 계산됩니다. ■ 멘토링(연 10시간 이내): CISA는 멘토링에 대해 연간 최대 10시간의 CPE를 이수한 것으로 인정 받을 수 있습니다. 이 활동에는 단체, 지부 또는 개인 차원에서 CISA 시험 준비를 지도, 검토 또는 보조하거나 자격 심사 과정을 통해 경력 관련 조언을 제공하는 것과 직접적으로 관련된 멘토링 활동이 포함됩니다. 멘토링 활동은 특정인의 ISACA 시험 준비 또는 자격증 관련 의사결정을 지원하는 활동이어야 합니다. 각 지원 시간 당 1시간의 CPE 시간을 이수한 것으로 인정됩니다. CPE 시간의 계산 매 50분간의 인정되는 ISACA 및 비 ISACA 전문 교육 활동 및 회의 참가(점심시간 및 휴식시간 제외)에 대해 1시간의 CPE를 이수한 것으로 간주됩니다. CPE 시간은 25분 단위로 이수한 것으로 간주되며 25분 단위로 보고될 수 있습니다(가까운 25분 단위로 절사). 예를 들어, 90분의 휴식시간이 포함된 8시간 프리젠테이션(480분)에 참가한 CISA는 7시간(7.75)의 지속적 전문 교육을 이수한 것으로 간주됩니다. 계산 예제 교육 활동 일정 실제 시간 분 오전 9시 – 오후 5시 8.0 480 제외: 15분 휴식 x 2회 <.50> <30> 제외: 점심 – 1시간 <1.0> <60> 총 전문 교육 활동 시간 6.5 390 CPE 시간 계산 390분을 50분으로 나누면 7.8 또는 7.75로 보고할 수 있는 CPE 시간이 나옵니다(가까운 25분 단위로 절사). 연락 정보 Certification Department 전화: +1.847.660.5660 ISACA 팩스: +1.847.253.1755 3701 Algonquin Road, Suite 1010 이메일: certification@isaca.org Rolling Meadows, Illinois 60008 USA 추가 정보 www.isaca.org/cisacpepolicy 6 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 ISACA 직업윤리강령 ISACA는 아래와 같은 직업윤리강령(Code of Professional Ethics)을 통해 협회 회원 및 자격증 소지자의 직업적이고 개인적인 행위에 대한 지침을 제시합니다. 이러한 직업윤리강령(Code of Professional Ethics)을 준수하지 못할 경우 회원 및/또는 자격증 소지자의 행위에 대한 조사에 이어 궁극적으로 징계 조치가 취해질 수 있습니다. ISACA 직업윤리강령은 www.isaca.org/ethics에서 참고하실 수 있습니다. 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 7 출석 확인서 CISA 지속적 전문 교육 CISA 자격증 번호: ___________________________________________________ ________________________________________________________ 은(는) 다음과 같이 전문 교육 활동에 참가했습니다. (이름) 제목: ___________________________________________________________________________________________________________ (프로그램/교과과정의 제목 또는 이름) 날짜: ______________________________________________________________ CPE 이수 시간: _____________________________ 후원자: _________________________________________________________________________________________________________ 내용: ___________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ _______________________________________________________________________________________________________________ 장소: ___________________________________________________________________________________________________________ *발표자 이름: ____________________________________________________________________________________________________ 서명: ___________________________________________________________________________________________________________ (발표자 또는 관계자) * 유의사항: 전문 활동의 발표자인 경우에는 해당 과정 후원자의 서명을 받으십시오. 8 국제 공인 정보시스템 감사사(CISA) 지속적 전문 교육 정책 : C IS A : : – C P E 기 록 양 식 (양 식 은 영 어 로 작 성 하 십 시 오 ) 3701 Algonquin Road, Suite 1010 Rolling Meadows, IL 60008 USA 전화: +1.847.253.1545 팩스: +1.847.253.1443 이메일: certification@isaca.org 웹 사이트: www.isaca.org DOC: CISA CPE 정책 버전: V4 갱신: 2014-0101"
50,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
51,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
52,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
53,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
54,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
55,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
56,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
57,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
58,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
59,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
60,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
61,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
62,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
63,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
64,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
65,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
66,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
67,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
68,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
69,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
70,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
71,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
72,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
73,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
74,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
75,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
76,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
77,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
78,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
79,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
80,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
81,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
82,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
83,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
84,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
85,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
86,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
87,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
88,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
89,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
90,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
91,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
92,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
93,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
94,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
95,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
96,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
97,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
98,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
99,"PowerPoint Presentation Spark Streaming Large-scale near-real-time stream processing Tathagata Das (TD) UC Berkeley UC BERKELEY What is Spark Streaming? Framework for large scale stream processing Scales to 100s of nodes Can achieve second scale latencies Integrates with Spark’s batch and interactive processing Provides a simple batch-like API for implementing complex algorithm Can absorb live data streams from Kafka, Flume, ZeroMQ, etc. Motivation Many important applications must process large streams of live data and provide results in near-real-time Social network trends Website statistics Intrustion detection systems etc. Require large clusters to handle workloads Require latencies of few seconds Need for a framework … … for building such complex stream processing applications But what are the requirements from such a framework? Requirements Scalable to large clusters Second-scale latencies Simple programming model Case study: Conviva, Inc. Real-time monitoring of online video metadata HBO, ESPN, ABC, SyFy, … Two processing stacks Custom-built distributed stream processing system 1000s complex metrics on millions of video sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Custom-built distributed stream processing system 1000s complex metrics on millions of videos sessions Requires many dozens of nodes for processing Hadoop backend for offline analysis Generating daily and monthly reports Similar computation as the streaming system Case study: XYZ, Inc. Any company who wants to process live streaming data has this problem Twice the effort to implement any new function Twice the number of bugs to solve Twice the headache Two processing stacks Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Stateful Stream Processing Traditional streaming systems have a event-driven record-at-a-time processing model Each node has mutable state For each record, update state & send new records State is lost if node dies! Making stateful stream processing be fault-tolerant is challenging * mutable state node 1 node 3 input records node 2 input records Traditional streaming systems have what we call a “record-at-a-time” processing model. Each node in the cluster processing a stream has a mutable state. As records arrive one at a time, the mutable state is updated, and a new generated record is pushed to downstream nodes. Now making this mutable state fault-tolerant is hard. * Existing Streaming Systems Storm Replays record if not processed by a node Processes each record at least once May update mutable state twice! Mutable state can be lost due to failure! Trident – Use transactions to update state Processes each record exactly once Per state transaction updates slow * Requirements Scalable to large clusters Second-scale latencies Simple programming model Integrated with batch & interactive processing Efficient fault-tolerance in stateful computations Spark Streaming * Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Chop up the live stream into batches of X seconds Spark treats each batch of data as RDDs and processes them using RDD operations Finally, the processed results of the RDD operations are returned in batches processed results Discretized Stream Processing Run a streaming computation as a series of very small, deterministic batch jobs * Spark Spark Streaming batches of X seconds live data stream Batch sizes as low as ½ second, latency ~ 1 second Potential for combining batch processing and streaming processing in the same system processed results Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) DStream: a sequence of RDD representing a stream of data tweets DStream stored in memory as an RDD (immutable, distributed) Twitter Streaming API batch @ t+1 batch @ t batch @ t+2 Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) transformation: modify data in one Dstream to create another DStream new DStream new RDDs created for every batch hashTags Dstream [#cat, #dog, … ] flatMap flatMap flatMap … batch @ t+1 batch @ t batch @ t+2 tweets DStream Example 1 – Get hashtags from Twitter val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") output operation: to push data to external storage flatMap flatMap flatMap batch @ t+1 batch @ t batch @ t+2 tweets DStream hashTags DStream every batch saved to HDFS save save save Java Example Scala val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Java JavaDStream<Status> tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) JavaDstream<String> hashTags = tweets.flatMap(new Function<...> { }) hashTags.saveAsHadoopFiles(""hdfs://..."") Function object to define the transformation Fault-tolerance RDDs are remember the sequence of operations that created it from the original fault-tolerant input data Batches of input data are replicated in memory of multiple worker nodes, therefore fault-tolerant Data lost due to worker failure, can be recomputed from input data input data replicated in memory flatMap lost partitions recomputed on other workers tweets RDD hashTags RDD Key concepts DStream – sequence of RDDs representing a stream of data Twitter, HDFS, Kafka, Flume, ZeroMQ, Akka Actor, TCP sockets Transformations – modify data from on DStream to another Standard RDD operations – map, countByValue, reduce, join, … Stateful operations – window, countByValueAndWindow, … Output Operations – send data to external entity saveAsHadoopFiles – saves to HDFS foreach – do anything with each batch of results Example 2 – Count the hashtags val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.countByValue() batch @ t+1 batch @ t batch @ t+2 hashTags tweets tagCounts [(#cat, 10), (#dog, 25), ... ] flatMap map reduceByKey flatMap map reduceByKey … flatMap map reduceByKey Example 3 – Count the hashtags over last 10 mins val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window operation window length sliding interval Example 3 – Counting the hashtags over last 10 mins val tagCounts = hashTags.window(Minutes(10), Seconds(1)).countByValue() sliding window countByValue count over all the data in the window tagCounts hashTags t-1 t t+1 t+2 t+3 ? Smart window-based countByValue val tagCounts = hashtags.countByValueAndWindow(Minutes(10), Seconds(1)) countByValue add the counts from the new batch in the window subtract the counts from batch before the window tagCounts hashTags t-1 t t+1 t+2 t+3 + + – Smart window-based reduce Technique to incrementally compute count generalizes to many reduce operations Need a function to “inverse reduce” (“subtract” for counting) Could have implemented counting as: hashTags.reduceByKeyAndWindow(_ + _, _ - _, Minutes(1), …) * Demo Fault-tolerant Stateful Processing All intermediate data are RDDs, hence can be recomputed if lost hashTags t-1 t t+1 t+2 t+3 tagCounts Fault-tolerant Stateful Processing State data not lost even if a worker node dies Does not change the value of your result Exactly once semantics to all transformations No double counting! * Other Interesting Operations Maintaining arbitrary state, track sessions Maintain per-user mood as state, and update it with his/her tweets tweets.updateStateByKey(tweet => updateMood(tweet)) Do arbitrary Spark RDD computation within DStream Join incoming tweets with a spam file to filter out bad tweets tweets.transform(tweetsRDD => { tweetsRDD.join(spamHDFSFile).filter(...) }) Performance Can process 6 GB/sec (60M records/sec) of data on 100 nodes at sub-second latency Tested with 100 streams of data on 100 EC2 instances with 4 cores each * Comparison with Storm and S4 Higher throughput than Storm Spark Streaming: 670k records/second/node Storm: 115k records/second/node Apache S4: 7.5k records/second/node * Streaming Spark offers similar speed while providing FT and consistency guarantees that these systems lack * Fast Fault Recovery Recovers from faults/stragglers within 1 sec * Real Applications: Conviva Real-time monitoring of video metadata * Achieved 1-2 second latency Millions of video sessions processed Scales linearly with cluster size Real Applications: Mobile Millennium Project Traffic transit time estimation using online machine learning on GPS observations * Markov chain Monte Carlo simulations on GPS observations Very CPU intensive, requires dozens of machines for useful computation Scales linearly with cluster size Vision - one stack to rule them all Spark + Shark + Spark Streaming Spark program vs Spark Streaming program Spark Streaming program on Twitter stream val tweets = ssc.twitterStream(<Twitter username>, <Twitter password>) val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFiles(""hdfs://..."") Spark program on Twitter log file val tweets = sc.hadoopFile(""hdfs://..."") val hashTags = tweets.flatMap (status => getTags(status)) hashTags.saveAsHadoopFile(""hdfs://..."") Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Vision - one stack to rule them all Explore data interactively using Spark Shell / PySpark to identify problems Use same code in Spark stand-alone programs to identify problems in production logs Use similar code in Spark Streaming to identify problems in live log streams $ ./spark-shell scala> val file = sc.hadoopFile(“smallLogs”) ... scala> val filtered = file.filter(_.contains(“ERROR”)) ... scala> val mapped = file.map(...) ... object ProcessProductionData { def main(args: Array[String]) { val sc = new SparkContext(...) val file = sc.hadoopFile(“productionLogs”) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } object ProcessLiveStream { def main(args: Array[String]) { val sc = new StreamingContext(...) val stream = sc.kafkaStream(...) val filtered = file.filter(_.contains(“ERROR”)) val mapped = file.map(...) ... } } Spark + Shark + Spark Streaming Alpha Release with Spark 0.7 Integrated with Spark 0.7 Import spark.streaming to get all the functionality Both Java and Scala API Give it a spin! Run locally or in a cluster Try it out in the hands-on tutorial later today Summary Stream processing framework that is ... Scalable to large clusters Achieves second-scale latencies Has simple programming model Integrates with batch & interactive workloads Ensures efficient fault-tolerance in stateful computations For more information, checkout our paper: http://tinyurl.com/dstreams"
